{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "466a47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f5ea01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y, C):\n",
    "  Y = sparse.coo_matrix((np.ones_like(y),\n",
    "  (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "  return Y\n",
    "\n",
    "def softmax_stable(Z):\n",
    "  e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True))\n",
    "  A = e_Z / e_Z.sum(axis = 0)\n",
    "  return A\n",
    "\n",
    "def softmax(Z):\n",
    "  e_Z = np.exp(Z)\n",
    "  A = e_Z / e_Z.sum(axis = 0)\n",
    "  return A\n",
    "\n",
    "def softmax_regression(X, y, W_init, eta, tol = 1e-4, max_count = 10000):\n",
    "  W = [W_init]\n",
    "  C = W_init.shape[1]\n",
    "  Y = convert_labels(y, C)\n",
    "  it = 0\n",
    "  N = X.shape[1]\n",
    "  d = X.shape[0]\n",
    "\n",
    "  count = 0\n",
    "  check_w_after = 20\n",
    "  while count < max_count:\n",
    "# mix data\n",
    "    mix_id = np.random.permutation(N)\n",
    "    for i in mix_id:\n",
    "      xi = X[:, i].reshape(d, 1)\n",
    "      yi = Y[:, i].reshape(C, 1)\n",
    "      ai = softmax(np.dot(W[-1].T, xi))\n",
    "      W_new = W[-1] + eta*xi.dot((yi - ai).T)\n",
    "      count += 1\n",
    "      # stopping criteria\n",
    "      if count%check_w_after == 0:\n",
    "        if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "          return W\n",
    "\n",
    "      W.append(W_new)\n",
    "  return W\n",
    "  \n",
    "def cost(X, Y, W):\n",
    "  A = softmax(W.T.dot(X))\n",
    "  return -np.sum(Y*np.log(A))\n",
    "\n",
    "def pred(W, X):\n",
    "  A = softmax_stable(W.T.dot(X))\n",
    "  return np.argmax(A, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7ba53454",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87cfdd",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f2ab62bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 120)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "flo_1X, flo_2X, flo_3X = X[:50, :], X[50:100, :], X[100:150, :]\n",
    "flo_1y, flo_2y, flo_3y = y[:50], y[50:100], y[100:150]\n",
    "\n",
    "idx1 = np.random.permutation(len(flo_1X))\n",
    "idx2 = np.random.permutation(len(flo_2X))\n",
    "idx3 = np.random.permutation(len(flo_3X))\n",
    "\n",
    "flo_1X, flo_1y = flo_1X[idx1], flo_1y[idx1]\n",
    "flo_2X, flo_2y = flo_2X[idx2], flo_2y[idx2]\n",
    "flo_3X, flo_3y = flo_3X[idx3], flo_3y[idx3]\n",
    "\n",
    "X_train = np.concatenate((flo_1X[:40], flo_2X[:40], flo_3X[:40])).T\n",
    "X_test  = np.concatenate((flo_1X[40:], flo_2X[40:], flo_3X[40:])).T\n",
    "y_train = np.concatenate((flo_1y[:40], flo_2y[:40], flo_3y[:40]))\n",
    "y_test  = np.concatenate((flo_1y[40:], flo_2y[40:], flo_3y[40:]))\n",
    "\n",
    "print(X_train.shape)  \n",
    "print(y_train.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5b1284f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(4, 30)\n"
     ]
    }
   ],
   "source": [
    "eta = 0.05\n",
    "C = 3\n",
    "d = X_train.shape[0]\n",
    "W_init = np.random.randn(d, C)\n",
    "W = softmax_regression(X_train, y_train, W_init, eta)\n",
    "print(W[-1].shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9fa1cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(W[-1], X_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "72d983e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9666666666666667\n",
      "precision:0.9696969696969697\n",
      "recall:0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f'accuracy:{accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision:{precision_score(y_test, y_pred,average='macro')}')\n",
    "print(f'recall:{recall_score(y_test, y_pred,average='macro')}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ff510",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb4ad545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def predict_NB_gaussian_class(X, mu_list, std_list, pi_list):\n",
    "  scores_list = []\n",
    "  classes = len(mu_list)\n",
    "  for c in range(classes):\n",
    "    score = norm.pdf(x = X[0], loc = mu_list[c][0][0], scale = std_list[c][0][0]) * norm.pdf(x = X[1], loc = mu_list[c][0][1], scale = std_list[c][0][1]) * norm.pdf(x = X[2], loc = mu_list[c][0][2], scale = std_list[c][0][2]) * norm.pdf(x = X[3], loc = mu_list[c][0][3], scale = std_list[c][0][3]) * pi_list[c]\n",
    "    scores_list.append(score)\n",
    "  return np.argmax(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f4afe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.T, X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "db8919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "mu_list = [X_train[y_train == c].mean(axis=0, keepdims=True) for c in classes]\n",
    "std_list = [X_train[y_train == c].std(axis=0, keepdims=True) for c in classes]\n",
    "pi_list = np.array([np.mean(y == c) for c in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b6c5e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(X_test.shape[0])\n",
    "for i in range(X_test.shape[0]):\n",
    "  y_pred[i] = predict_NB_gaussian_class(X_test[i, :], mu_list, std_list, pi_list).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "68d53d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9333333333333333\n",
      "precision:0.9444444444444445\n",
      "recall:0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy:{accuracy_score(y_test, y_pred)}')\n",
    "print(f'precision:{precision_score(y_test, y_pred,average='macro')}')\n",
    "print(f'recall:{recall_score(y_test, y_pred,average='macro')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13466a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
