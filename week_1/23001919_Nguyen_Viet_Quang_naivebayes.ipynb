{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b534e273",
   "metadata": {},
   "source": [
    "# Câu 1: Phân loại tập dữ liệu Iris với 4 thuộc tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d40c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6f0977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris = iris.rename(index=str, columns={'sepal_length':'1_sepal_length','sepal_width':'2_sepal_width', 'petal_length':'3_petal_length', 'petal_width':'4_petal_width'})\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6488f",
   "metadata": {},
   "source": [
    "Lấy dữ liệu thủ công với mỗi loại hoa lấy 80% là tập training, 20% là tập test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9272466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15758/2048182279.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_labels = df1.iloc[:, 4].replace({'setosa':0, 'versicolor':1, 'virginica':2}).copy()\n"
     ]
    }
   ],
   "source": [
    "df1 = iris[[\"1_sepal_length\", \"2_sepal_width\", \"3_petal_length\", \"4_petal_width\", \"species\"]]\n",
    "X = df1[[\"1_sepal_length\", \"2_sepal_width\", \"3_petal_length\", \"4_petal_width\"]]\n",
    "y = df1['species']\n",
    "df_test = pd.concat([df1[40:50], df1[90:100], df1[140:150]])\n",
    "X_train = pd.concat([df1[0:40], df1[50:90], df1[100:140]]).drop(['species'], axis = 1)\n",
    "X_test = pd.concat([df1[40:50], df1[90:100], df1[140:150]]).drop(['species'], axis = 1)\n",
    "\n",
    "\n",
    "y_labels = df1.iloc[:, 4].replace({'setosa':0, 'versicolor':1, 'virginica':2}).copy()\n",
    "y_train = pd.concat([y_labels[0:40], y_labels[50:90], y_labels[100:140]])\n",
    "y_test = pd.concat([y_labels[40:50], y_labels[90:100], y_labels[140:150]])\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10779197",
   "metadata": {},
   "source": [
    "Hàm thực hiện thuật toán NB:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce157c61",
   "metadata": {},
   "source": [
    "Ta đã xác định được rằng các trường trong tập dữ liệu là đại lượng ngẫu nhiên liên tục, với giả thiết các trường tuân theo phân phối chuẩn và các trường độc lập với nhau, ta có công thức tính score như ở dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c59e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def predict_NB_gaussian_class(X, mu_list, std_list, pi_list):\n",
    "  scores_list = []\n",
    "  classes = len(mu_list)\n",
    "  for c in range(classes):\n",
    "    score = norm.pdf(x = X[0], loc = mu_list[c][0][0], scale = std_list[c][0][0]) * norm.pdf(x = X[1], loc = mu_list[c][0][1], scale = std_list[c][0][1]) * norm.pdf(x = X[2], loc = mu_list[c][0][2], scale = std_list[c][0][2]) * norm.pdf(x = X[3], loc = mu_list[c][0][3], scale = std_list[c][0][3]) * pi_list[c]\n",
    "    scores_list.append(score)\n",
    "  \n",
    "  return np.argmax(scores_list)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bfd71",
   "metadata": {},
   "source": [
    "Thực hiện việc lấy giá trị trung bình, độ lệch chuẩn, xác suất của từng lớp pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8991d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[5.006, 3.428, 1.462, 0.246]]), array([[5.936, 2.77 , 4.26 , 1.326]]), array([[6.588, 2.974, 5.552, 2.026]])]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mu_list = np.split(df1.groupby('species').mean().values,[1,2])\n",
    "std_list = np.split(df1.groupby('species').std().values,[1,2], axis = 0)\n",
    "pi_list = df1.iloc[:,4].value_counts().values / len(df1)\n",
    "print(mu_list)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4052c8",
   "metadata": {},
   "source": [
    "Thực hiện thuật toán NB trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9cb91c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15758/3962004731.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  score = norm.pdf(x = X[0], loc = mu_list[c][0][0], scale = std_list[c][0][0]) * norm.pdf(x = X[1], loc = mu_list[c][0][1], scale = std_list[c][0][1]) * norm.pdf(x = X[2], loc = mu_list[c][0][2], scale = std_list[c][0][2]) * norm.pdf(x = X[3], loc = mu_list[c][0][3], scale = std_list[c][0][3]) * pi_list[c]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(X_test.shape[0])\n",
    "for i in range(X_test.shape[0]):\n",
    "  y_pred[i] = predict_NB_gaussian_class(X_test.iloc[i, :], mu_list, std_list, pi_list)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce65d24",
   "metadata": {},
   "source": [
    "Tính accuracy giữa kết quả dự đoán và kết quả thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b8c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Recall : 1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_pred, y_test))\n",
    "print('Recall :', recall_score(y_pred, y_test, average='macro'))\n",
    "print('Precision: ', precision_score(y_pred, y_test, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_pred, y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b60593",
   "metadata": {},
   "source": [
    "## Sử dụng thư viện sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e60786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X, y, train_size=0.8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a77661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Recall : 1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train_lib, y_train_lib)\n",
    "y_pred = model.predict(X_test_lib)\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test_lib))\n",
    "print('Recall :', recall_score(y_pred, y_test_lib, average='macro'))\n",
    "print('Precision: ', precision_score(y_pred, y_test_lib, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_pred, y_test_lib, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3132c",
   "metadata": {},
   "source": [
    "# Câu 2: Phân loại bệnh nhân ung thư"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371b8ac",
   "metadata": {},
   "source": [
    "Đọc dữ liệu từ file, xử lý dữ liệu và phân chia dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8da78f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 120 579 120\n",
      "1       int64\n",
      "2       int64\n",
      "3       int64\n",
      "4       int64\n",
      "5       int64\n",
      "6     float64\n",
      "7       int64\n",
      "8       int64\n",
      "9       int64\n",
      "10      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/vitquay1708/Study_Space/ml/week_1/data/breast-cancer-wisconsin.data', header=None)\n",
    "df = df.drop(0, axis = 1) # Bỏ cột 0 là mã số mẫu vì không liên quan tới bài toán\n",
    "#Ép các cột (trừ cột label về số)\n",
    "for col in df.columns[:-1]:\n",
    "  df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "df = df.fillna(df.mean()) # Ghi đè các giá trị Nan bằng trung bình với giả thiết các trường dữ liệu được phân phối theo phân bố chuẩn\n",
    "benign = df[df[10] == 2]\n",
    "malignant = df[df[10] == 4]\n",
    "#Lấy 80 dòng ngẫu nhiên của lành tính và 40 dòng ngẫu nhiên của ác tính\n",
    "benign_test = benign.sample(n = 80, random_state=17)\n",
    "malignant_test = malignant.sample(n = 40, random_state=17)\n",
    "\n",
    "#Lấy phần còn lại của lành tính và ác tính làm tập train\n",
    "benign_train = benign.drop(benign_test.index)\n",
    "malignant_train = malignant.drop(malignant_test.index)\n",
    "# Gộp train và test vào làm X_train, X_test, y_train, y_test\n",
    "X_train = pd.concat([benign_train.iloc[:, :9], malignant_train.iloc[:, :9]], axis=0)\n",
    "y_train = pd.concat([benign_train.iloc[:, 9], malignant_train.iloc[:, 9]], axis=0)\n",
    "X_test = pd.concat([benign_test.iloc[:, :9], malignant_test.iloc[:, :9]], axis=0)\n",
    "y_test = pd.concat([benign_test.iloc[:, 9], malignant_test.iloc[:, 9]], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "# print(X_train)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1fe75a",
   "metadata": {},
   "source": [
    "Hàm dự đoán Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d8d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NB_gaussian_class(X,mu_list,std_list,pi_list):\n",
    "#Returns the class for which the Gaussian Naive Bayes objective function has greatest value\n",
    "    scores_list = []\n",
    "    classes = len(mu_list)\n",
    "    for p in range(classes):\n",
    "        score = (norm.pdf(x = X[0], loc = mu_list[p][0][0], scale = std_list[p][0][0])\n",
    "        * norm.pdf(x = X[1], loc = mu_list[p][0][1], scale = std_list[p][0][1])\n",
    "        * norm.pdf(x = X[2], loc = mu_list[p][0][2], scale = std_list[p][0][2])\n",
    "        * norm.pdf(x = X[3], loc = mu_list[p][0][3], scale = std_list[p][0][3] )\n",
    "        * norm.pdf(x = X[4], loc = mu_list[p][0][4], scale = std_list[p][0][4])\n",
    "        * norm.pdf(x = X[5], loc = mu_list[p][0][5], scale = std_list[p][0][5])\n",
    "        * norm.pdf(x = X[6], loc = mu_list[p][0][6], scale = std_list[p][0][6])\n",
    "        * norm.pdf(x = X[7], loc = mu_list[p][0][7], scale = std_list[p][0][7])\n",
    "        * norm.pdf(x = X[8], loc = mu_list[p][0][8], scale = std_list[p][0][8] )\n",
    "        * pi_list[p])\n",
    "        scores_list.append(score)\n",
    "        \n",
    "    return 2 if np.argmax(scores_list) == 0 else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d28370",
   "metadata": {},
   "source": [
    "Tính giá trị trung bình, độ lệch chuẩn, xác suất theo từng lớp của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f030dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.85146805, 2.44905009, 2.57858377, 2.2193437 , 2.75474957,\n",
      "        2.78879878, 3.00345423, 2.18480138, 2.46286701]]), array([[ 7.08571429,  4.88571429,  4.8       ,  4.14285714,  3.8       ,\n",
      "         6.91428571,  4.77142857,  5.54285714,  3.54285714],\n",
      "       [ 7.21212121,  6.6969697 ,  6.48484848,  5.60606061,  5.81818182,\n",
      "         7.33333333,  5.63636364,  5.81818182,  3.87878788],\n",
      "       [ 7.16666667,  6.66666667,  5.66666667,  7.5       ,  5.5       ,\n",
      "         7.91666667,  5.33333333,  7.33333333,  4.        ],\n",
      "       [ 6.33333333,  6.83333333,  7.        ,  5.66666667,  5.        ,\n",
      "         7.33333333,  5.83333333,  4.        ,  3.66666667],\n",
      "       [ 8.        ,  8.33333333,  7.66666667,  5.        ,  5.33333333,\n",
      "        10.        ,  7.33333333,  8.        ,  4.        ],\n",
      "       [ 6.        ,  6.88888889,  7.11111111,  7.33333333,  6.66666667,\n",
      "         7.55555556,  6.22222222,  6.88888889,  3.77777778],\n",
      "       [ 6.75      ,  6.5       ,  7.125     ,  5.375     ,  5.25      ,\n",
      "         6.375     ,  6.375     ,  4.875     ,  3.75      ],\n",
      "       [ 8.28571429,  8.64285714,  8.07142857,  7.07142857,  8.14285714,\n",
      "         6.5       ,  5.92857143,  8.28571429,  4.        ]])]\n",
      "[array([[2.52846297, 2.587315  , 2.55092576, 2.31556466, 1.80789045,\n",
      "        3.14249795, 2.19939953, 2.49123941, 0.84422693]]), array([[2.57100837, 2.77352429, 2.73108468, 3.02093536, 1.79541901,\n",
      "        3.47572615, 2.42639547, 3.53422641, 0.85208592],\n",
      "       [2.31513466, 2.66323169, 2.61152748, 3.39060645, 2.5794203 ,\n",
      "        3.4247871 , 2.1624376 , 3.06649785, 0.48461168],\n",
      "       [2.6571801 , 2.46182982, 2.67423169, 3.06000594, 1.16774842,\n",
      "        3.60450055, 1.55699789, 3.05505046, 0.        ],\n",
      "       [2.94392029, 3.76386326, 4.        , 3.88158043, 3.03315018,\n",
      "        4.17931414, 3.54494946, 3.68781778, 0.81649658],\n",
      "       [1.        , 2.081666  , 4.04145188, 4.35889894, 0.57735027,\n",
      "        0.        , 0.57735027, 3.46410162, 0.        ],\n",
      "       [2.73861279, 3.48010217, 3.25747005, 3.16227766, 3.082207  ,\n",
      "        3.04594448, 3.03223423, 3.78960567, 0.66666667],\n",
      "       [3.57571172, 3.50509833, 2.94897076, 3.5831949 , 3.15096357,\n",
      "        3.85217935, 2.82526863, 2.85043856, 0.70710678],\n",
      "       [1.97789987, 2.13423172, 2.94734002, 3.79198113, 2.31573689,\n",
      "        3.71587033, 2.84102597, 2.86701591, 0.        ]])]\n",
      "[0.65522175 0.34477825]\n"
     ]
    }
   ],
   "source": [
    "mu_list = np.split(df.groupby(9).mean().values, [1])\n",
    "std_list = np.split(df.groupby(9).std().values, [1], axis=0)\n",
    "pi_list = df.iloc[:, 9].value_counts().values / len(df)\n",
    "print(mu_list)\n",
    "print(std_list)\n",
    "print(pi_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6c39",
   "metadata": {},
   "source": [
    "Thực hiện tính toán phân loại trên tập train và tập test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bd7d2",
   "metadata": {},
   "source": [
    "Tập train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e82349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train):  0.9309153713298791\n",
      "Precision (train):  0.9707602339181286\n",
      "Recall (train):  0.8258706467661692\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.zeros(X_train.shape[0])\n",
    "for i in range(X_train.shape[0]):\n",
    "    x = X_train.iloc[i].values\n",
    "    y_train_pred[i] = predict_NB_gaussian_class(x, mu_list, std_list, pi_list)\n",
    "print('Accuracy (train): ', accuracy_score(y_train, y_train_pred))\n",
    "print('Precision (train): ', precision_score(y_train, y_train_pred, pos_label=4))\n",
    "print('Recall (train): ', recall_score(y_train, y_train_pred, pos_label=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de9a26",
   "metadata": {},
   "source": [
    "Tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffdcdc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test):  0.9666666666666667\n",
      "Precision (test):  1.0\n",
      "Recall (test):  0.9\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.zeros(X_test.shape[0])\n",
    "# print(X_train.iloc[0].values.reshape(-1, 1))\n",
    "for i in range(X_test.shape[0]):\n",
    "    x = X_test.iloc[i].values\n",
    "    y_test_pred[i] = predict_NB_gaussian_class(x, mu_list, std_list, pi_list)\n",
    "print('Accuracy (test): ', accuracy_score(y_test, y_test_pred))\n",
    "print('Precision (test): ', precision_score(y_test, y_test_pred, pos_label=4))\n",
    "print('Recall (test): ', recall_score(y_test, y_test_pred, pos_label=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058057b8",
   "metadata": {},
   "source": [
    "## Sử dụng thư viện Scikit Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "335885ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n",
      "1.0\n",
      "0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "sklearn_y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(sklearn_y_test_pred, y_test))\n",
    "print(precision_score(sklearn_y_test_pred, y_test, pos_label=4))\n",
    "print(recall_score(sklearn_y_test_pred, y_test, pos_label=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e6045",
   "metadata": {},
   "source": [
    "# Câu 3: Dự đoán loại ẩm thực"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d5784",
   "metadata": {},
   "source": [
    "Đọc dữ liệu từ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9215ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cuisine     city device user_segment    promo fav_ingredient  \\\n",
      "0    american  city_16    web          new  promo_1          onion   \n",
      "1        thai  city_10    ios       family  promo_7       cilantro   \n",
      "2    american  city_18    ios      student  promo_1         cheese   \n",
      "3    japanese  city_10    web       family  promo_3         ginger   \n",
      "4  vietnamese  city_10    web       family     none     fish_sauce   \n",
      "\n",
      "  spice_level day_of_week price_bucket  \n",
      "0         hot         Wed         high  \n",
      "1        mild         Wed          mid  \n",
      "2         hot         Fri          mid  \n",
      "3        mild         Tue         high  \n",
      "4        mild         Wed          low  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/vitquay1708/Study_Space/ml/week_1/data/multinomial_nb_orders.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc23ec",
   "metadata": {},
   "source": [
    "Tính xác suất P(c) = Nc/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91cbd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['cuisine']\n",
    "y_labels = np.zeros((len(set(Y)), 2), dtype=Y.dtype)\n",
    "i = 0\n",
    "for label in set(Y):\n",
    "  y_labels[i, 0] = label\n",
    "  y_labels[i, 1] = (Y == label).sum() / len(Y)\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0de35",
   "metadata": {},
   "source": [
    "Tính toán xác suất P(xi|k) cùng với phương pháp Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8951c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cuisine' 10]\n",
      " ['city' 20]\n",
      " ['device' 5]\n",
      " ['user_segment' 6]\n",
      " ['promo' 9]\n",
      " ['fav_ingredient' 18]\n",
      " ['spice_level' 5]\n",
      " ['day_of_week' 7]\n",
      " ['price_bucket' 4]]\n"
     ]
    }
   ],
   "source": [
    "def get_unique_value_in_col(df: pd.DataFrame):\n",
    "  #Lấy ra tên của các trường trong DataFrame\n",
    "  col_names = df.columns.values\n",
    "  #Tạo một mảng 2 chiều lưu trữ tên cột và số giá trị phân biệt của cột đó\n",
    "  unique_values = np.zeros((len(col_names), 2), dtype=col_names.dtype)\n",
    "  #Đặt cột đầu tiên là tên của các cột\n",
    "  unique_values[:, 0] = col_names\n",
    "\n",
    "  #Lấy ra số lượng các giá trị phân biệt trong từng cột rồi gán vào cột thứ 2\n",
    "  for i in range(len(col_names)):\n",
    "    unique = set(df[col_names[i]])\n",
    "    unique_values[i, 1] = len(unique)\n",
    "\n",
    "  return unique_values\n",
    "\n",
    "num_labels_M = get_unique_value_in_col(df=df)\n",
    "print(num_labels_M)\n",
    "\n",
    "def pxik_for_feature_each_class(X, xi, num_nomials_M, alpha = 1.0):\n",
    "  X = np.array(X)\n",
    "  count = (X==xi).sum()\n",
    "  return (count + alpha)/(len(X) + num_nomials_M*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dca092",
   "metadata": {},
   "source": [
    "Dự đoán output đầu ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a850c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output_label(df, X, x_input, p_labels, target_feature):\n",
    "  num_labels_M = get_unique_value_in_col(df)\n",
    "  #Mảng p chứa loga của xác suất tiên nghiệm\n",
    "  p = np.log(np.array(p_labels[:, 1], dtype=float))\n",
    "  for k in range(len(p)):\n",
    "    #Xk[c] chứa toàn bộ dữ liệu thuộc lớp c\n",
    "    Xk = X[X[target_feature] == p_labels[k, 0]]\n",
    "    for i in range(len(x_input)):\n",
    "      #Công thức xác suất dự đoán sử dụng Laplace Smoothing\n",
    "      p[k] += np.log(pxik_for_feature_each_class(Xk.iloc[:, i+1], x_input.iloc[i], num_labels_M[i + 1, 1]))\n",
    "  \n",
    "  y_star = np.argmax(p)\n",
    "  return p_labels[y_star, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdc094",
   "metadata": {},
   "source": [
    "Chia train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3a646ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(df) * 0.7)\n",
    "target_col = 'cuisine'\n",
    "X_train = df[:train_size]\n",
    "y_train = df[target_col][:train_size]\n",
    "\n",
    "X_test = df[train_size:].drop(target_col,axis=1).reset_index(drop=True, inplace=False)\n",
    "y_test = df[target_col][train_size:].reset_index(drop=True, inplace=False)\n",
    "\n",
    "y_pred = np.zeros(len(y_test), dtype=y_test.dtype)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "  y_pred[i] = predict_output_label(df, X_train, X_test.iloc[i, :], y_labels, target_feature=target_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "040b6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49\n",
      "chinese\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(predict_output_label(df, X_train, X_train.iloc[3, 1:], y_labels, target_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06199878",
   "metadata": {},
   "source": [
    "# Sử dụng thư viện Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d889341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "938b26f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train_lib = X_train.drop(target_col, axis=1, inplace=False)\n",
    "# print(X_train_lib)\n",
    "encoder1 = OneHotEncoder()\n",
    "X_train_encoded = encoder1.fit_transform(X_train_lib)\n",
    "X_test_encoded = encoder1.transform(X_test)\n",
    "\n",
    "encoder2 = LabelEncoder()\n",
    "y_train_encoded = encoder2.fit_transform(y_train)\n",
    "y_test_encoded = encoder2.transform(y_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "print('accuracy_score:', accuracy_score(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12846523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
